---
layout: post
title: K-nearest neighbors
tags: [machine learning]

---
<!-- TOC -->
### <a href="#-machine-learning">1. Machine Learning là gì</a>
#### <a href="#-nhiem-vu">1.1. Nhiệm vụ</a>
#### <a href="#-danh-gia">1.2. Đánh giá</a>
#### <a href="#-kinh-nghiem">1.3. Kinh nghiệm</a>
### <a href="#-nearest-neighbor">2. _K_ - Nearest Neighbors</a>
<!-- END TOC -->


Hôm nay nói một ít về công nghệ machine learning và một phương pháp để "máy học" - K-nearest neighbors (_k_-NNs).

<a name="-machine-learning">

### Machine learning là gì ?

Machine learning hay tiếng Việt là *Học máy*. Chính là để cho một chương trình máy tính có thể học hỏi từ *kinh nghiệm E* để thực hiện *nhiệm vụ T* với hiệu quả được đo bằng *phép đánh giá P*

Được chia thành học có giám sát và học không giám sát.

<a name="-nhiem-vu">

#### Nhiệm vụ

Những nhiệm vụ bao gồm:

 *Phân loại* hay *Classification*

 *Hồi quy* hay *Regression*

 *Phân nhóm* hay *Clustering*

 *Phiên dịch* hay *Translation*

 *Điền* hay *Completion*
 
<a name="-danh-gia">

#### Đánh giá 

Đánh giá hiệu quả của một mô hình machine learning được xây dựng bằng tập kiểm thử (*test set*)

<a name="-kinh-nghiem">

#### Kinh nghiệm 

Dựa trên tập huấn luyện (*training set*) xây dựng mô hình học cho máy.

<a name="-nearest-neighbor">

### K-Nearest Neighbors

Còn được gọi là *Lazy learning*, là một thuật toán học có giám sát, một dạng thuật toán đơn giản nhất. Kiểu học máy móc, nước tới ngực mới bơi, dự đoán dữ liệu mới thông qua các dữ liệu ở gần. 

Việc dự đoán này dựa trên khoảng cách giữa các điểm thuộc training set đối với điểm dự đoán. Có hai thuộc tính khoảng các là *distance* và *uniform*. Distance đưa lại mức độ chính xác tốt hơn nhưng cũng dễ gây *overfitting* hơn.

Ví dụ tính toán khoảng cách giữa điểm **z** đến một điểm **x** bất kỳ trong training set.

{% highlight python linenos %}
from __future__ import print_function
import numpy as np 

d, N = 1000, 10000
X = np.random.randn(N, d) # N, d: numbers and dimensions
z = np.random.randn(d)

def dist_pp(z, x):	# tính khoảng cách theo Euclid
	p = z - x.reshape(z.shape)
	return np.sum(p*p)

def dist_ps_naive(z, X): 
	M = X.shape[0]
	res = np.zeros((1, M))
	for i in range(M):
		res[0][i] = dist_pp(z, X[i])
	return res
	
# tính khoảng cách từ z đến lần lượt tùng điểm trong X

def dist_ps_fast(z, X):
	a = np.sum(z*z)
	b = np.sum(X*X, 1)
	return a + b - 2*b.dot(a)
	
# tính khoảng cách thông qua norm

{% endhighlight %}

Với những khoảng cách phức tạp hơn như khoảng các từ nhiều điểm _**Z**_ đến nhiều điểm _**X**_ cần phải có những phương pháp tính hợp lý tránh tốn quá nhiều thời gian.

{% highlight python linenos %}
M = 100
Z = np.random.randn(M, d)

def dist_naive(Z, X):
	M = Z.shape[0]
	N = X.shape[0]
	res = np.zeros((M, N))
	for i in range(M):
		res = dist_ps_fast(Z[i], X)
	return res

def dist_fast(Z, X):
	a = np.sum(Z*Z, 1)
	b = np.sum(X*X, 1)
	return a.reshape(-1, 1) + b.reshape(1, -1) - 2*Z.dot(X.T)
{% endhighlight %}

KNN trong scikit-learn

{% highlight python linenos %}
from __future__ import print_function
from sklearn import datasets, neighbors
import numpy as np
from sklearn.mode_selection import train_test_split
from sklearn.metrics import accuracy_score
{% endhighlight %}
